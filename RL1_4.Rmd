# NTUTrainRL1_4
This is the lecture notes for NTU Train Course of R Project Lecture 1_4

## Data Collection

### 讀取csv

這是實務中最常運用的方法，csv as in comma-separated values。

```{r}
setwd("C:/NTUTrainRL1")
Sys.setlocale(category = "LC_ALL", locale = "cht")#csv檔是繁體中文
accidentList <- read.csv("data/funCoastAccident.csv", header=TRUE, sep=",")
head(accidentList)#看看前6筆資料
str(accidentList)#看看資料集結構
```

欄位屬性可以在讀取資料時設定。

```{r}
accidentList <- read.csv("data/funCoastAccident.csv", header=TRUE, sep=",", row.names="編號", colClasses=c("character", "character", "character", "character", "character", "integer", "factor", "factor"))
colnames(accidentList) <- c("county", "hospital", "gender", "nationality", "age", "woundType1", "woundType2")
```

### 讀取excel

我們需要仰賴xlsx套件才能夠讀取excel檔案。

```{r}
install.packages("xlsx")
library(xlsx)
accidentList <- read.xlsx("C:/NTUTrainRL1/data/funCoastAccident.xlsx", 1)
```

### 讀取sas資料集

我們需要仰賴Hmisc套件才能夠讀取excel檔案。

```{r}
library(Hmisc)
datadir <- "C:/NTUTrainRL1/data"
sasexe <- "C:/Program Files/SASHome/SASFoundation/9.4/sas.exe"
accidentList <- sas.get(libraryName=datadir, member="funcoastaccident", sasprog=sasexe)
```

### 抓取網頁資料
網頁爬蟲是一個專門的研究領域，這裡只有時間很快地簡介，有興趣的學員可以去選修木刻思專門為蟲友開的課程。

#### 工欲善其事

我們要先裝一些好用的網頁瀏覽器外掛來幫助我們爬網頁:

#### Connector

#### Parser

## Reference
* R in Action, Robert I. Kabacoff
* The Art of R Programming, Norman Matloff

&copy; Tony Yao-Jen Kuo 2015